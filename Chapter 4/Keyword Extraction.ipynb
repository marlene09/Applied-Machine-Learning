{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword extraction with `TfidfVectorizer`\n",
    "\n",
    "Scikit-learn's `CountVectorizer` class creates matrices of word counts and is frequently uses in text-classification tasks. The related [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class creates matrices of [Term Freqeuency-Inverse Document Frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (TFIDF) values that reflect not just the presence of individual words, but each word's importance. One use for `TfidfVectorizer` is extracting keywords from documents. Let's use it to extract keywords from a book chapter on machine learning. Begin by loading the chapter from a text file and showing the first few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Machine Learning?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n",
       "0            Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.\n",
       "1  Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.\n",
       "2                  To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What is Machine Learning?\n",
       "4                                                                                    At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/chapter-1.txt', sep='\\r\\n', engine='python', header=None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the paragraphs and show the first few lines of the resulting word matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1s 0s</th>\n",
       "      <th>add column</th>\n",
       "      <th>annual income</th>\n",
       "      <th>build mathematical</th>\n",
       "      <th>cat dog</th>\n",
       "      <th>classification models</th>\n",
       "      <th>column contains</th>\n",
       "      <th>credit card</th>\n",
       "      <th>data data</th>\n",
       "      <th>data points</th>\n",
       "      <th>...</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>setosa versicolor</th>\n",
       "      <th>spending score</th>\n",
       "      <th>spending scores</th>\n",
       "      <th>supervised learning</th>\n",
       "      <th>train machine</th>\n",
       "      <th>training data</th>\n",
       "      <th>unsupervised learning</th>\n",
       "      <th>use following</th>\n",
       "      <th>versicolor virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297392</td>\n",
       "      <td>0.257343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.727929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.670370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1s 0s  add column  annual income  build mathematical   cat dog  \\\n",
       "0  0.000000         0.0            0.0            0.000000  1.000000   \n",
       "1  0.000000         0.0            0.0            0.526645  0.000000   \n",
       "2  0.000000         0.0            0.0            0.000000  0.329181   \n",
       "3  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "4  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "5  0.727929         0.0            0.0            0.000000  0.000000   \n",
       "6  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "7  0.670370         0.0            0.0            0.000000  0.000000   \n",
       "8  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "9  0.000000         0.0            0.0            0.000000  0.000000   \n",
       "\n",
       "   classification models  column contains  credit card  data data  \\\n",
       "0                    0.0          0.00000          0.0        0.0   \n",
       "1                    0.0          0.00000          0.0        0.0   \n",
       "2                    0.0          0.00000          0.0        0.0   \n",
       "3                    0.0          0.00000          0.0        0.0   \n",
       "4                    0.0          0.00000          0.0        0.0   \n",
       "5                    0.0          0.40287          0.0        0.0   \n",
       "6                    0.0          0.00000          0.0        0.0   \n",
       "7                    0.0          0.00000          0.0        0.0   \n",
       "8                    0.0          0.00000          0.0        0.0   \n",
       "9                    0.0          0.00000          0.0        0.0   \n",
       "\n",
       "   data points  ...  sepal width  setosa versicolor  spending score  \\\n",
       "0          0.0  ...          0.0                0.0             0.0   \n",
       "1          0.0  ...          0.0                0.0             0.0   \n",
       "2          0.0  ...          0.0                0.0             0.0   \n",
       "3          0.0  ...          0.0                0.0             0.0   \n",
       "4          0.0  ...          0.0                0.0             0.0   \n",
       "5          0.0  ...          0.0                0.0             0.0   \n",
       "6          0.0  ...          0.0                0.0             0.0   \n",
       "7          0.0  ...          0.0                0.0             0.0   \n",
       "8          0.0  ...          0.0                0.0             0.0   \n",
       "9          0.0  ...          0.0                0.0             0.0   \n",
       "\n",
       "   spending scores  supervised learning  train machine  training data  \\\n",
       "0              0.0                  0.0       0.000000       0.000000   \n",
       "1              0.0                  0.0       0.000000       0.411714   \n",
       "2              0.0                  0.0       0.297392       0.257343   \n",
       "3              0.0                  0.0       0.000000       0.000000   \n",
       "4              0.0                  0.0       0.000000       0.000000   \n",
       "5              0.0                  0.0       0.000000       0.000000   \n",
       "6              0.0                  0.0       0.000000       0.000000   \n",
       "7              0.0                  0.0       0.000000       0.000000   \n",
       "8              0.0                  0.0       0.000000       0.000000   \n",
       "9              0.0                  0.0       0.000000       0.000000   \n",
       "\n",
       "   unsupervised learning  use following  versicolor virginica  \n",
       "0                    0.0            0.0                   0.0  \n",
       "1                    0.0            0.0                   0.0  \n",
       "2                    0.0            0.0                   0.0  \n",
       "3                    0.0            0.0                   0.0  \n",
       "4                    0.0            0.0                   0.0  \n",
       "5                    0.0            0.0                   0.0  \n",
       "6                    0.0            0.0                   0.0  \n",
       "7                    0.0            0.0                   0.0  \n",
       "8                    0.0            0.0                   0.0  \n",
       "9                    0.0            0.0                   0.0  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2), min_df=0.025, max_df=0.5, stop_words='english')\n",
    "word_matrix = vectorizer.fit_transform(df[0])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "wm_df = pd.DataFrame(data=word_matrix.toarray(), columns=feature_names)\n",
    "wm_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sparse word matrix into a coordinate matrix that includes only non-zero values (weights) and the rows and columns in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<COOrdinate sparse matrix of dtype 'float64'\n",
      "\twith 264 stored elements and shape (97, 53)>\n",
      "  Coords\tValues\n",
      "  (0, 4)\t1.0\n",
      "  (1, 25)\t0.28712873491214824\n",
      "  (1, 21)\t0.43970283823932543\n",
      "  (1, 3)\t0.5266452223745365\n",
      "  (1, 28)\t0.5266452223745365\n",
      "  (1, 49)\t0.41171364214971173\n",
      "  (2, 4)\t0.329181214354719\n",
      "  (2, 25)\t0.7178827918222094\n",
      "  (2, 21)\t0.2748376100218393\n",
      "  (2, 49)\t0.25734287700964276\n",
      "  (2, 48)\t0.2973922436659566\n",
      "  (2, 22)\t0.2656032729771943\n",
      "  (2, 20)\t0.2748376100218393\n",
      "  (3, 25)\t1.0\n",
      "  (4, 25)\t0.7939808859869445\n",
      "  (4, 26)\t0.6079427215514522\n",
      "  (5, 0)\t0.7279293690706851\n",
      "  (5, 10)\t0.4028697432073993\n",
      "  (5, 18)\t0.38145874437527655\n",
      "  (5, 6)\t0.4028697432073993\n",
      "  (6, 25)\t0.6290045370685583\n",
      "  (6, 37)\t0.5211465511802166\n",
      "  (6, 30)\t0.5768531568260111\n",
      "  (7, 0)\t0.6703697701710424\n",
      "  (7, 30)\t0.7420272038414925\n",
      "  :\t:\n",
      "  (91, 40)\t1.0\n",
      "  (93, 25)\t0.5141811959491369\n",
      "  (93, 21)\t0.3937030741581843\n",
      "  (93, 3)\t0.47154993101664194\n",
      "  (93, 28)\t0.47154993101664194\n",
      "  (93, 49)\t0.3686419838367718\n",
      "  (94, 25)\t0.1414101320845122\n",
      "  (94, 26)\t0.21655246888606403\n",
      "  (94, 5)\t0.24558675593114754\n",
      "  (94, 23)\t0.6278294062758754\n",
      "  (94, 50)\t0.19150502328554675\n",
      "  (94, 47)\t0.39376023290373574\n",
      "  (94, 19)\t0.46864782871828475\n",
      "  (94, 7)\t0.25937135995965965\n",
      "  (95, 21)\t0.24889386407501618\n",
      "  (95, 20)\t0.49778772815003236\n",
      "  (95, 50)\t0.22010566529441708\n",
      "  (95, 47)\t0.45256702170434626\n",
      "  (95, 29)\t0.22628351085217313\n",
      "  (95, 40)\t0.2822643258872808\n",
      "  (95, 38)\t0.29810761494812055\n",
      "  (95, 32)\t0.4661011500283529\n",
      "  (96, 25)\t0.3983271671474636\n",
      "  (96, 29)\t0.5545762379110629\n",
      "  (96, 17)\t0.7306029456939581\n"
     ]
    }
   ],
   "source": [
    "coo_matrix = word_matrix.tocoo()\n",
    "print(coo_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tuples from the column numbers and weights in the coordinate matrix. Then sort the tuples in descending order based on the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int32(4), np.float64(1.0)) => cat dog\n",
      "(np.int32(25), np.float64(1.0)) => machine learning\n",
      "(np.int32(25), np.float64(1.0)) => machine learning\n",
      "(np.int32(25), np.float64(1.0)) => machine learning\n",
      "(np.int32(25), np.float64(1.0)) => machine learning\n",
      "(np.int32(50), np.float64(1.0)) => unsupervised learning\n",
      "(np.int32(12), np.float64(1.0)) => following code\n",
      "(np.int32(29), np.float64(1.0)) => means clustering\n",
      "(np.int32(29), np.float64(1.0)) => means clustering\n",
      "(np.int32(9), np.float64(1.0)) => data points\n",
      "(np.int32(47), np.float64(1.0)) => supervised learning\n",
      "(np.int32(32), np.float64(1.0)) => nearest neighbors\n",
      "(np.int32(32), np.float64(1.0)) => nearest neighbors\n",
      "(np.int32(32), np.float64(1.0)) => nearest neighbors\n",
      "(np.int32(32), np.float64(1.0)) => nearest neighbors\n",
      "(np.int32(31), np.float64(1.0)) => model accuracy\n",
      "(np.int32(27), np.float64(1.0)) => making predictions\n",
      "(np.int32(36), np.float64(1.0)) => predict class\n",
      "(np.int32(49), np.float64(1.0)) => training data\n",
      "(np.int32(40), np.float64(1.0)) => scikit learn\n",
      "(np.int32(32), np.float64(0.8805448238444277)) => nearest neighbors\n",
      "(np.int32(37), np.float64(0.8561751021506758)) => real world\n",
      "(np.int32(25), np.float64(0.803856205496376)) => machine learning\n",
      "(np.int32(25), np.float64(0.7939808859869445)) => machine learning\n",
      "(np.int32(49), np.float64(0.7731187523324384)) => training data\n",
      "(np.int32(39), np.float64(0.7676246648600459)) => right number\n",
      "(np.int32(2), np.float64(0.7500525583741241)) => annual income\n",
      "(np.int32(32), np.float64(0.7441198535306922)) => nearest neighbors\n",
      "(np.int32(30), np.float64(0.7420272038414925)) => millions rows\n",
      "(np.int32(6), np.float64(0.7420272038414925)) => column contains\n",
      "(np.int32(9), np.float64(0.7399158628045803)) => data points\n",
      "(np.int32(13), np.float64(0.7376325237851317)) => following statements\n",
      "(np.int32(19), np.float64(0.7353775931681876)) => labeled data\n",
      "(np.int32(37), np.float64(0.7344073797929055)) => real world\n",
      "(np.int32(17), np.float64(0.7306029456939581)) => jupyter notebook\n",
      "(np.int32(0), np.float64(0.7279293690706851)) => 1s 0s\n",
      "(np.int32(46), np.float64(0.7218931373084843)) => spending scores\n",
      "(np.int32(25), np.float64(0.7178827918222094)) => machine learning\n",
      "(np.int32(29), np.float64(0.7168242079334923)) => means clustering\n",
      "(np.int32(29), np.float64(0.7168242079334923)) => means clustering\n",
      "(np.int32(23), np.float64(0.7084869306845735)) => learning models\n",
      "(np.int32(39), np.float64(0.7071067811865476)) => right number\n",
      "(np.int32(33), np.float64(0.7071067811865476)) => number clusters\n",
      "(np.int32(39), np.float64(0.7071067811865476)) => right number\n",
      "(np.int32(33), np.float64(0.7071067811865476)) => number clusters\n",
      "(np.int32(41), np.float64(0.7071067811865476)) => segment customers\n",
      "(np.int32(1), np.float64(0.7071067811865476)) => add column\n",
      "(np.int32(5), np.float64(0.7037578744864946)) => classification models\n",
      "(np.int32(50), np.float64(0.6972539386195831)) => unsupervised learning\n",
      "(np.int32(50), np.float64(0.6972539386195831)) => unsupervised learning\n",
      "(np.int32(50), np.float64(0.6939068212915545)) => unsupervised learning\n",
      "(np.int32(25), np.float64(0.6845742955493805)) => machine learning\n",
      "(np.int32(48), np.float64(0.6801256079913934)) => train machine\n",
      "(np.int32(20), np.float64(0.6787089217814357)) => learning algorithm\n",
      "(np.int32(51), np.float64(0.6752023843666262)) => use following\n",
      "(np.int32(29), np.float64(0.6726994246839768)) => means clustering\n",
      "(np.int32(0), np.float64(0.6703697701710424)) => 1s 0s\n",
      "(np.int32(0), np.float64(0.6703697701710424)) => 1s 0s\n",
      "(np.int32(9), np.float64(0.6613782273982346)) => data points\n",
      "(np.int32(0), np.float64(0.6503674936951619)) => 1s 0s\n",
      "(np.int32(37), np.float64(0.6503674936951619)) => real world\n",
      "(np.int32(9), np.float64(0.6408996597740573)) => data points\n",
      "(np.int32(29), np.float64(0.6373134305385414)) => means clustering\n",
      "(np.int32(17), np.float64(0.6359354687693229)) => jupyter notebook\n",
      "(np.int32(25), np.float64(0.6290045370685583)) => machine learning\n",
      "(np.int32(23), np.float64(0.6278294062758754)) => learning models\n",
      "(np.int32(41), np.float64(0.6241007262832584)) => segment customers\n",
      "(np.int32(50), np.float64(0.619913912867442)) => unsupervised learning\n",
      "(np.int32(26), np.float64(0.6079427215514522)) => make predictions\n",
      "(np.int32(22), np.float64(0.6074253494015961)) => learning model\n",
      "(np.int32(20), np.float64(0.6026409911330227)) => learning algorithm\n",
      "(np.int32(13), np.float64(0.6021379106039388)) => following statements\n",
      "(np.int32(27), np.float64(0.6014439028675274)) => making predictions\n",
      "(np.int32(23), np.float64(0.594823672095326)) => learning models\n",
      "(np.int32(15), np.float64(0.5875716412871428)) => income spending\n",
      "(np.int32(45), np.float64(0.5875716412871428)) => spending score\n",
      "(np.int32(15), np.float64(0.5875716412871428)) => income spending\n",
      "(np.int32(45), np.float64(0.5875716412871428)) => spending score\n",
      "(np.int32(12), np.float64(0.5851682335794984)) => following code\n",
      "(np.int32(46), np.float64(0.5851682335794984)) => spending scores\n",
      "(np.int32(30), np.float64(0.5768531568260111)) => millions rows\n",
      "(np.int32(31), np.float64(0.5657375217907783)) => model accuracy\n",
      "(np.int32(47), np.float64(0.565650896047802)) => supervised learning\n",
      "(np.int32(49), np.float64(0.564279999559708)) => training data\n",
      "(np.int32(32), np.float64(0.564279999559708)) => nearest neighbors\n",
      "(np.int32(12), np.float64(0.5638314313493283)) => following code\n",
      "(np.int32(51), np.float64(0.5613878132083908)) => use following\n",
      "(np.int32(30), np.float64(0.5595611884647269)) => millions rows\n",
      "(np.int32(11), np.float64(0.5595611884647269)) => datasets like\n",
      "(np.int32(25), np.float64(0.5578013866175753)) => machine learning\n",
      "(np.int32(2), np.float64(0.5563444371163124)) => annual income\n",
      "(np.int32(2), np.float64(0.5563444371163124)) => annual income\n",
      "(np.int32(29), np.float64(0.5545762379110629)) => means clustering\n",
      "(np.int32(40), np.float64(0.5497781594090745)) => scikit learn\n",
      "(np.int32(48), np.float64(0.5433625732975231)) => train machine\n",
      "(np.int32(51), np.float64(0.5409181088439146)) => use following\n",
      "(np.int32(18), np.float64(0.5298226336223203)) => label column\n",
      "(np.int32(3), np.float64(0.5266452223745365)) => build mathematical\n",
      "(np.int32(28), np.float64(0.5266452223745365)) => mathematical models\n",
      "(np.int32(11), np.float64(0.5262313216431029)) => datasets like\n",
      "(np.int32(8), np.float64(0.5262313216431029)) => data data\n",
      "(np.int32(31), np.float64(0.5262313216431029)) => model accuracy\n",
      "(np.int32(21), np.float64(0.524171258635692)) => learning algorithms\n",
      "(np.int32(37), np.float64(0.5211465511802166)) => real world\n",
      "(np.int32(25), np.float64(0.5166857792288073)) => machine learning\n",
      "(np.int32(25), np.float64(0.5141811959491369)) => machine learning\n",
      "(np.int32(6), np.float64(0.5134579738259717)) => column contains\n",
      "(np.int32(11), np.float64(0.5134579738259717)) => datasets like\n",
      "(np.int32(41), np.float64(0.5115535290919585)) => segment customers\n",
      "(np.int32(37), np.float64(0.5111043510219243)) => real world\n",
      "(np.int32(33), np.float64(0.5065949667294068)) => number clusters\n",
      "(np.int32(15), np.float64(0.5065949667294068)) => income spending\n",
      "(np.int32(45), np.float64(0.5065949667294068)) => spending score\n",
      "(np.int32(23), np.float64(0.506559498473125)) => learning models\n",
      "(np.int32(10), np.float64(0.5018640752209794)) => data scientists\n",
      "(np.int32(38), np.float64(0.5018640752209794)) => regression classification\n",
      "(np.int32(42), np.float64(0.5)) => sepal length\n",
      "(np.int32(43), np.float64(0.5)) => sepal width\n",
      "(np.int32(34), np.float64(0.5)) => petal length\n",
      "(np.int32(35), np.float64(0.5)) => petal width\n",
      "(np.int32(47), np.float64(0.4998901342511416)) => supervised learning\n",
      "(np.int32(20), np.float64(0.49778772815003236)) => learning algorithm\n",
      "(np.int32(18), np.float64(0.4861696299796273)) => label column\n",
      "(np.int32(5), np.float64(0.4861696299796273)) => classification models\n",
      "(np.int32(22), np.float64(0.48528124372751885)) => learning model\n",
      "(np.int32(29), np.float64(0.4827173253309481)) => means clustering\n",
      "(np.int32(2), np.float64(0.4796713656799762)) => annual income\n",
      "(np.int32(26), np.float64(0.47234149947909015)) => make predictions\n",
      "(np.int32(3), np.float64(0.47154993101664194)) => build mathematical\n",
      "(np.int32(28), np.float64(0.47154993101664194)) => mathematical models\n",
      "(np.int32(8), np.float64(0.46990818526810524)) => data data\n",
      "(np.int32(19), np.float64(0.46864782871828475)) => labeled data\n",
      "(np.int32(22), np.float64(0.4684928198408405)) => learning model\n",
      "(np.int32(32), np.float64(0.4661011500283529)) => nearest neighbors\n",
      "(np.int32(0), np.float64(0.4621528967566216)) => 1s 0s\n",
      "(np.int32(46), np.float64(0.4621528967566216)) => spending scores\n",
      "(np.int32(25), np.float64(0.45775357113688714)) => machine learning\n",
      "(np.int32(3), np.float64(0.45593647959569067)) => build mathematical\n",
      "(np.int32(28), np.float64(0.45593647959569067)) => mathematical models\n",
      "(np.int32(10), np.float64(0.45593647959569067)) => data scientists\n",
      "(np.int32(47), np.float64(0.45256702170434626)) => supervised learning\n",
      "(np.int32(49), np.float64(0.4422746959462308)) => training data\n",
      "(np.int32(29), np.float64(0.4407419595440168)) => means clustering\n",
      "(np.int32(21), np.float64(0.43970283823932543)) => learning algorithms\n",
      "(np.int32(14), np.float64(0.4309876875284723)) => high incomes\n",
      "(np.int32(16), np.float64(0.4309876875284723)) => incomes low\n",
      "(np.int32(24), np.float64(0.4309876875284723)) => low spending\n",
      "(np.int32(50), np.float64(0.4287091086012696)) => unsupervised learning\n",
      "(np.int32(25), np.float64(0.42717466671388643)) => machine learning\n",
      "(np.int32(21), np.float64(0.4190127412341422)) => learning algorithms\n",
      "(np.int32(20), np.float64(0.4190127412341422)) => learning algorithm\n",
      "(np.int32(20), np.float64(0.4128385301026845)) => learning algorithm\n",
      "(np.int32(36), np.float64(0.4119067757311599)) => predict class\n",
      "(np.int32(49), np.float64(0.41171364214971173)) => training data\n",
      "(np.int32(49), np.float64(0.4113900683843245)) => training data\n",
      "(np.int32(25), np.float64(0.4104431778683697)) => machine learning\n",
      "(np.int32(8), np.float64(0.40699193453118504)) => data data\n",
      "(np.int32(25), np.float64(0.40628159595485386)) => machine learning\n",
      "(np.int32(10), np.float64(0.4028697432073993)) => data scientists\n",
      "(np.int32(6), np.float64(0.4028697432073993)) => column contains\n",
      "(np.int32(14), np.float64(0.39952901367606747)) => high incomes\n",
      "(np.int32(16), np.float64(0.39952901367606747)) => incomes low\n",
      "(np.int32(24), np.float64(0.39952901367606747)) => low spending\n",
      "(np.int32(22), np.float64(0.3989674659070634)) => learning model\n",
      "(np.int32(25), np.float64(0.3983271671474636)) => machine learning\n",
      "(np.int32(21), np.float64(0.3973533763410001)) => learning algorithms\n",
      "(np.int32(9), np.float64(0.3973533763410001)) => data points\n",
      "(np.int32(47), np.float64(0.39376023290373574)) => supervised learning\n",
      "(np.int32(21), np.float64(0.3937030741581843)) => learning algorithms\n",
      "(np.int32(14), np.float64(0.3933255742665142)) => high incomes\n",
      "(np.int32(16), np.float64(0.3933255742665142)) => incomes low\n",
      "(np.int32(24), np.float64(0.3933255742665142)) => low spending\n",
      "(np.int32(1), np.float64(0.3933255742665142)) => add column\n",
      "(np.int32(25), np.float64(0.3924847083509714)) => machine learning\n",
      "(np.int32(26), np.float64(0.39233235961520574)) => make predictions\n",
      "(np.int32(27), np.float64(0.3917571980615879)) => making predictions\n",
      "(np.int32(17), np.float64(0.38982155623635906)) => jupyter notebook\n",
      "(np.int32(1), np.float64(0.38982155623635906)) => add column\n",
      "(np.int32(44), np.float64(0.38982155623635906)) => setosa versicolor\n",
      "(np.int32(52), np.float64(0.38982155623635906)) => versicolor virginica\n",
      "(np.int32(12), np.float64(0.38936728402848236)) => following code\n",
      "(np.int32(46), np.float64(0.38936728402848236)) => spending scores\n",
      "(np.int32(18), np.float64(0.38145874437527655)) => label column\n",
      "(np.int32(47), np.float64(0.3809482187543103)) => supervised learning\n",
      "(np.int32(9), np.float64(0.38066720368441453)) => data points\n",
      "(np.int32(23), np.float64(0.37915028732924827)) => learning models\n",
      "(np.int32(51), np.float64(0.37354394099375515)) => use following\n",
      "(np.int32(7), np.float64(0.3725963921963298)) => credit card\n",
      "(np.int32(13), np.float64(0.37242181181412043)) => following statements\n",
      "(np.int32(4), np.float64(0.3716296432513177)) => cat dog\n",
      "(np.int32(49), np.float64(0.3686419838367718)) => training data\n",
      "(np.int32(26), np.float64(0.3665595920155999)) => make predictions\n",
      "(np.int32(47), np.float64(0.36125646319792865)) => supervised learning\n",
      "(np.int32(18), np.float64(0.3554970719708412)) => label column\n",
      "(np.int32(46), np.float64(0.3553421942731911)) => spending scores\n",
      "(np.int32(48), np.float64(0.35392527587640576)) => train machine\n",
      "(np.int32(19), np.float64(0.35392527587640576)) => labeled data\n",
      "(np.int32(36), np.float64(0.35392527587640576)) => predict class\n",
      "(np.int32(48), np.float64(0.35217655863424213)) => train machine\n",
      "(np.int32(12), np.float64(0.35217655863424213)) => following code\n",
      "(np.int32(51), np.float64(0.3409015834018214)) => use following\n",
      "(np.int32(19), np.float64(0.33661482558875183)) => labeled data\n",
      "(np.int32(36), np.float64(0.3357414354155537)) => predict class\n",
      "(np.int32(42), np.float64(0.33039136954762116)) => sepal length\n",
      "(np.int32(43), np.float64(0.33039136954762116)) => sepal width\n",
      "(np.int32(34), np.float64(0.33039136954762116)) => petal length\n",
      "(np.int32(35), np.float64(0.33039136954762116)) => petal width\n",
      "(np.int32(44), np.float64(0.33039136954762116)) => setosa versicolor\n",
      "(np.int32(52), np.float64(0.33039136954762116)) => versicolor virginica\n",
      "(np.int32(4), np.float64(0.329181214354719)) => cat dog\n",
      "(np.int32(22), np.float64(0.32838565863700264)) => learning model\n",
      "(np.int32(25), np.float64(0.32790922544088724)) => machine learning\n",
      "(np.int32(25), np.float64(0.3165651252016762)) => machine learning\n",
      "(np.int32(22), np.float64(0.31609335369122366)) => learning model\n",
      "(np.int32(23), np.float64(0.31609335369122366)) => learning models\n",
      "(np.int32(38), np.float64(0.31463809884674654)) => regression classification\n",
      "(np.int32(42), np.float64(0.31463809884674654)) => sepal length\n",
      "(np.int32(43), np.float64(0.31463809884674654)) => sepal width\n",
      "(np.int32(34), np.float64(0.31463809884674654)) => petal length\n",
      "(np.int32(35), np.float64(0.31463809884674654)) => petal width\n",
      "(np.int32(44), np.float64(0.31463809884674654)) => setosa versicolor\n",
      "(np.int32(52), np.float64(0.31463809884674654)) => versicolor virginica\n",
      "(np.int32(22), np.float64(0.3145315610321252)) => learning model\n",
      "(np.int32(9), np.float64(0.3134687305313628)) => data points\n",
      "(np.int32(13), np.float64(0.31283232137684347)) => following statements\n",
      "(np.int32(26), np.float64(0.3110854978001608)) => make predictions\n",
      "(np.int32(47), np.float64(0.3089339527615277)) => supervised learning\n",
      "(np.int32(25), np.float64(0.30507462960625437)) => machine learning\n",
      "(np.int32(23), np.float64(0.3006332589811739)) => learning models\n",
      "(np.int32(50), np.float64(0.30049963847799754)) => unsupervised learning\n",
      "(np.int32(23), np.float64(0.29985322757978966)) => learning models\n",
      "(np.int32(36), np.float64(0.29848553438944664)) => predict class\n",
      "(np.int32(38), np.float64(0.29810761494812055)) => regression classification\n",
      "(np.int32(5), np.float64(0.2979162772641291)) => classification models\n",
      "(np.int32(40), np.float64(0.2979162772641291)) => scikit learn\n",
      "(np.int32(48), np.float64(0.2973922436659566)) => train machine\n",
      "(np.int32(47), np.float64(0.29736977431594175)) => supervised learning\n",
      "(np.int32(49), np.float64(0.290527640721641)) => training data\n",
      "(np.int32(25), np.float64(0.28712873491214824)) => machine learning\n",
      "(np.int32(51), np.float64(0.2863554988284656)) => use following\n",
      "(np.int32(40), np.float64(0.2822643258872808)) => scikit learn\n",
      "(np.int32(47), np.float64(0.28209162126329296)) => supervised learning\n",
      "(np.int32(26), np.float64(0.2758479840847236)) => make predictions\n",
      "(np.int32(50), np.float64(0.2751039311925828)) => unsupervised learning\n",
      "(np.int32(21), np.float64(0.2748376100218393)) => learning algorithms\n",
      "(np.int32(20), np.float64(0.2748376100218393)) => learning algorithm\n",
      "(np.int32(25), np.float64(0.26958617175642563)) => machine learning\n",
      "(np.int32(22), np.float64(0.2656032729771943)) => learning model\n",
      "(np.int32(20), np.float64(0.2626953767041883)) => learning algorithm\n",
      "(np.int32(7), np.float64(0.25937135995965965)) => credit card\n",
      "(np.int32(49), np.float64(0.25734287700964276)) => training data\n",
      "(np.int32(21), np.float64(0.24889386407501618)) => learning algorithms\n",
      "(np.int32(25), np.float64(0.24857809209082235)) => machine learning\n",
      "(np.int32(32), np.float64(0.2459735551215709)) => nearest neighbors\n",
      "(np.int32(5), np.float64(0.24558675593114754)) => classification models\n",
      "(np.int32(29), np.float64(0.22628351085217313)) => means clustering\n",
      "(np.int32(50), np.float64(0.22010566529441708)) => unsupervised learning\n",
      "(np.int32(7), np.float64(0.21951968586736945)) => credit card\n",
      "(np.int32(26), np.float64(0.21655246888606403)) => make predictions\n",
      "(np.int32(25), np.float64(0.21253201496629096)) => machine learning\n",
      "(np.int32(19), np.float64(0.1983207092692564)) => labeled data\n",
      "(np.int32(50), np.float64(0.19150502328554675)) => unsupervised learning\n",
      "(np.int32(50), np.float64(0.16208081940968688)) => unsupervised learning\n",
      "(np.int32(25), np.float64(0.1414101320845122)) => machine learning\n"
     ]
    }
   ],
   "source": [
    "tuples = list(zip(coo_matrix.col, coo_matrix.data))\n",
    "sorted_tuples = sorted(tuples, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for _, tuple in enumerate(sorted_tuples):\n",
    "    print(f'{tuple} => {feature_names[tuple[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by weight and use `set` to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat dog', 'machine learning'}\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "num_keywords = 5\n",
    "\n",
    "for tuple in sorted_tuples[:num_keywords]:\n",
    "    keywords.append(feature_names[tuple[0]])\n",
    "    \n",
    "print(set(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword extraction sometimes works better when you sum all the values for a given word and select the words yielding the highest sums rather than the words with the highest individual values. Sort keywords based on that criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning             13.819216\n",
      "nearest neighbors             6.901019\n",
      "means clustering              6.447980\n",
      "unsupervised learning         5.286333\n",
      "supervised learning           4.542468\n",
      "training data                 4.519290\n",
      "data points                   4.133683\n",
      "learning models               3.733430\n",
      "real world                    3.273201\n",
      "learning model                3.184781\n",
      "1s 0s                         3.181189\n",
      "learning algorithm            3.148522\n",
      "following code                2.890544\n",
      "use following                 2.778309\n",
      "learning algorithms           2.697675\n",
      "make predictions              2.642662\n",
      "spending scores               2.513924\n",
      "predict class                 2.400059\n",
      "annual income                 2.342413\n",
      "train machine                 2.226982\n",
      "right number                  2.181838\n",
      "scikit learn                  2.129959\n",
      "labeled data                  2.092886\n",
      "model accuracy                2.091969\n",
      "following statements          2.025025\n",
      "making predictions            1.993201\n",
      "number clusters               1.920809\n",
      "millions rows                 1.878442\n",
      "segment customers             1.842761\n",
      "jupyter notebook              1.756360\n",
      "label column                  1.752948\n",
      "classification models         1.733431\n",
      "cat dog                       1.700811\n",
      "spending score                1.681738\n",
      "income spending               1.681738\n",
      "column contains               1.658355\n",
      "datasets like                 1.599250\n",
      "add column                    1.490254\n",
      "mathematical models           1.454132\n",
      "build mathematical            1.454132\n",
      "data data                     1.403131\n",
      "data scientists               1.360670\n",
      "high incomes                  1.223842\n",
      "low spending                  1.223842\n",
      "incomes low                   1.223842\n",
      "petal length                  1.145029\n",
      "sepal width                   1.145029\n",
      "sepal length                  1.145029\n",
      "petal width                   1.145029\n",
      "regression classification     1.114610\n",
      "setosa versicolor             1.034851\n",
      "versicolor virginica          1.034851\n",
      "credit card                   0.851487\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "summed_weights = pd.Series(dtype='float32')\n",
    "\n",
    "for col_name, col_data in wm_df.items():\n",
    "    summed_weights = pd.concat([summed_weights, pd.Series({ col_name: np.sum(col_data) })])\n",
    "    \n",
    "sorted_summed_weights = summed_weights.sort_values(ascending=False)\n",
    "print(sorted_summed_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by summed weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning', 'nearest neighbors', 'means clustering', 'unsupervised learning', 'supervised learning']\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "\n",
    "for idx, _ in sorted_summed_weights[:num_keywords].items():\n",
    "    keywords.append(idx)\n",
    "    \n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read **chapter-1.txt**, you'll see that these keywords highlight some of the most important concepts introduced in the chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
