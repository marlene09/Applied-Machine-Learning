{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c1b10e",
   "metadata": {},
   "source": [
    "Using pretrained models from hugging face\n",
    "Hugging Face started out in the research and NLP community, which — by 2019 onward — had already largely standardised on PyTorch because it’s:\n",
    "\n",
    "Easier for rapid prototyping (Pythonic, flexible, transparent).\n",
    "\n",
    "Dynamic (operations happen immediately, no static computation graph like in early TensorFlow).\n",
    "\n",
    "Popular in academia, so new models and papers almost always come with PyTorch code.\n",
    "\n",
    "When Hugging Face launched the Transformers library, most pretrained models (e.g. BERT, GPT-2, RoBERTa, etc.) were published in PyTorch first.\n",
    "So PyTorch became the default — but they still support TensorFlow for deployment and interoperability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59af613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is installed! Version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch is installed! Version:\", torch.__version__)\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cf74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marlenepostop/Documents/Applied-Machine-Learning/tf_mps/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0\n",
      "MPS available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9960187077522278}]\n"
     ]
    }
   ],
   "source": [
    "import torch  # Must come first\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "model = pipeline(\"sentiment-analysis\", framework=\"pt\")\n",
    "\n",
    "print(model(\"I love this movie!\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf272156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/marlenepostop/Documents/Applied-Machine-Learning/tf_mps/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"bhadresh-savani/bert-base-uncased-emotion\",\n",
    "    framework=\"pt\",           # <-- Force PyTorch\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36913b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'sadness', 'score': 0.9843235611915588},\n",
       "  {'label': 'joy', 'score': 0.0005428867880254984},\n",
       "  {'label': 'love', 'score': 0.0004259873239789158},\n",
       "  {'label': 'anger', 'score': 0.00543729355558753},\n",
       "  {'label': 'fear', 'score': 0.008960106410086155},\n",
       "  {'label': 'surprise', 'score': 0.0003100936010014266}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"The weather was gloomy, and there was a persistent drizzle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846af175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
